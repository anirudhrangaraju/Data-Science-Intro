{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "import pickle\n",
    "\n",
    "#Text Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "#Other Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.text\n",
    "y = data.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Extraction\n",
    "y = data['author']\n",
    "X = data['text']\n",
    "Category = pd.DataFrame(data.author)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train_nb, X_validate_nb, y_train_nb, y_validate_nb =  train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Building\n",
    "model_nb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "model_nb.fit(X_train_nb, y_train_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the file\n",
    "with open (\"model_nb.pkl\",\"wb\") as f:\n",
    "    pickle.dump(model_nb,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation\n",
    "predicted_nb_score = model_nb.predict(X_validate_nb)\n",
    "predicted_nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_output = pd.DataFrame(predicted_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Metrics Report\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_validate_nb,predicted_nb_score))\n",
    "print(metrics.classification_report(y_validate_nb,predicted_nb_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naiveBayes():\n",
    "    data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")\n",
    "    \n",
    "    #Data Extraction\n",
    "    y = data['author']\n",
    "    X = data['text']\n",
    "    Category = pd.DataFrame(data.author)[:]\n",
    "    \n",
    "    \n",
    "    #Train Test Split\n",
    "    X_train_nb, X_validate_nb, y_train_nb, y_validate_nb =  train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 0)\n",
    "    \n",
    "    \n",
    "    #Model Building\n",
    "    model_nb = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "    model_nb.fit(X_train_nb, y_train_nb)\n",
    "    \n",
    "    #save the file\n",
    "    with open (\"model_nb.pkl\",\"wb\") as f:\n",
    "        pickle.dump(model_nb,f)\n",
    "        \n",
    "    #Validation\n",
    "    predicted_nb_score = model_nb.predict(X_validate_nb)\n",
    "    predicted_nb_score\n",
    "    \n",
    "    predicted_output = pd.DataFrame(predicted_nb_score)\n",
    "    \n",
    "    #Metrics Report\n",
    "    from sklearn import metrics\n",
    "    print(metrics.confusion_matrix(y_validate_nb,predicted_nb_score))\n",
    "    print(metrics.classification_report(y_validate_nb,predicted_nb_score))\n",
    "    \n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm():\n",
    "    data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")\n",
    "    \n",
    "    #Data Extraction\n",
    "    y = data['author']\n",
    "    X = data['text']\n",
    "    Category = pd.DataFrame(data.author)[:]\n",
    "    \n",
    "    \n",
    "    #Train Test Split\n",
    "    X_train_svm, X_validate_svm, y_train_svm, y_validate_svm =  train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 0)\n",
    "    \n",
    "    \n",
    "    #Model Building\n",
    "    model_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier()),\n",
    "    ])\n",
    "\n",
    "    model_svm.fit(X_train_svm, y_train_svm)\n",
    "    \n",
    "    #save the file\n",
    "    with open (\"model_svm.pkl\",\"wb\") as f:\n",
    "        pickle.dump(model_svm,f)\n",
    "        \n",
    "    #Validation\n",
    "    predicted_svm_score = model_svm.predict(X_validate_svm)\n",
    "    predicted_svm_score\n",
    "    \n",
    "    predicted_output = pd.DataFrame(predicted_svm_score)\n",
    "    \n",
    "    #Metrics Report\n",
    "    from sklearn import metrics\n",
    "    print(metrics.confusion_matrix(y_validate_svm,predicted_svm_score))\n",
    "    print(metrics.classification_report(y_validate_svm,predicted_svm_score))\n",
    "    \n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decsionTree():\n",
    "    data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")\n",
    "    \n",
    "    #Data Extraction\n",
    "    y = data['author']\n",
    "    X = data['text']\n",
    "    Category = pd.DataFrame(data.author)[:]\n",
    "    \n",
    "    \n",
    "    #Train Test Split\n",
    "    X_train_dt, X_validate_dt, y_train_dt, y_validate_dt =  train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 0)\n",
    "    \n",
    "    \n",
    "    #Model Building\n",
    "    model_dt = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', DecisionTreeClassifier()),\n",
    "    ])\n",
    "\n",
    "    model_dt.fit(X_train_dt, y_train_dt)\n",
    "    \n",
    "    #save the file\n",
    "    with open (\"model_dt.pkl\",\"wb\") as f:\n",
    "        pickle.dump(model_dt,f)\n",
    "        \n",
    "    #Validation\n",
    "    predicted_dt_score = model_dt.predict(X_validate_dt)\n",
    "    predicted_dt_score\n",
    "    \n",
    "    predicted_output = pd.DataFrame(predicted_dt_score)\n",
    "    \n",
    "    #Metrics Report\n",
    "    from sklearn import metrics\n",
    "    print(metrics.confusion_matrix(y_validate_dt,predicted_dt_score))\n",
    "    print(metrics.classification_report(y_validate_dt,predicted_dt_score))\n",
    "    \n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decsionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")\n",
    "    \n",
    "    #Data Extraction\n",
    "    y = data['author']\n",
    "    X = data['text']\n",
    "    Category = pd.DataFrame(data.author)[:]\n",
    "    \n",
    "    \n",
    "    #Train Test Split\n",
    "    X_train_rf, X_validate_rf, y_train_rf, y_validate_rf =  train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 0)\n",
    "    \n",
    "    \n",
    "    #Model Building\n",
    "    model_rf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', DecisionTreeClassifier()),\n",
    "    ])\n",
    "\n",
    "    model_rf.fit(X_train_rf, y_train_rf)\n",
    "    \n",
    "    #save the file\n",
    "    with open (\"model_rf.pkl\",\"wb\") as f:\n",
    "        pickle.dump(model_rf,f)\n",
    "        \n",
    "    #Validation\n",
    "    predicted_rf_score = model_rf.predict(X_validate_rf)\n",
    "    predicted_rf_score\n",
    "    \n",
    "    predicted_output = pd.DataFrame(predicted_rf_score)\n",
    "    \n",
    "    #Metrics Report\n",
    "    from sklearn import metrics\n",
    "    print(metrics.confusion_matrix(y_validate_rf,predicted_rf_score))\n",
    "    print(metrics.classification_report(y_validate_rf,predicted_rf_score))\n",
    "    \n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomForest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Comparison of Multipe Algorithms ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\\\Users\\\\A\\\\Desktop\\\\spooky_identification\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.text\n",
    "y = data.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train,y_validate = train_test_split(X,y,test_size=.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, linear_model, neighbors, svm, tree\n",
    "\n",
    "from sklearn import svm,model_selection, tree, linear_model, naive_bayes, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    #Tree Based Classifiers\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    \n",
    "    #Linear Models\n",
    "    linear_model.LogisticRegression(),\n",
    "\n",
    "    #Naive Bayes Classifiers\n",
    "    naive_bayes.MultinomialNB(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos = [\"Random Forest Classifier\",\"Decision Tree Classifier\",\"Logistic Regression\",\"Naive Bayes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_result = []\n",
    "recall_result = []\n",
    "fscore_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\A\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    #Model Building\n",
    "    clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', clf),\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_predictions = clf.predict(X_validate)\n",
    "    precision = precision_score(y_validate, train_predictions,average='weighted')\n",
    "    precision_result.append(precision)\n",
    "\n",
    "    recall = recall_score(y_validate, train_predictions,average='weighted')\n",
    "    recall_result.append(recall)\n",
    "    \n",
    "    fscore = f1_score(y_validate, train_predictions,average='weighted')\n",
    "    fscore_result.append(fscore)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.821952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.803345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.632284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.540331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Precision_score\n",
       "Naive Bayes                      0.821952\n",
       "Logistic Regression              0.803345\n",
       "Random Forest Classifier         0.632284\n",
       "Decision Tree Classifier         0.540331"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_result = pd.DataFrame(precision_result,index=algos)\n",
    "precision_result.columns=[\"Precision_score\"]\n",
    "precision_result.sort_values(by=\"Precision_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.799591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.796527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.610827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.540756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          recall_score\n",
       "Logistic Regression           0.799591\n",
       "Naive Bayes                   0.796527\n",
       "Random Forest Classifier      0.610827\n",
       "Decision Tree Classifier      0.540756"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_result = pd.DataFrame(recall_result,index=algos)\n",
    "recall_result.columns=[\"recall_score\"]\n",
    "recall_result.sort_values(by=\"recall_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.799498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.795301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.602581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.539780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fscore_score\n",
       "Logistic Regression           0.799498\n",
       "Naive Bayes                   0.795301\n",
       "Random Forest Classifier      0.602581\n",
       "Decision Tree Classifier      0.539780"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore_result = pd.DataFrame(fscore_result,index=algos)\n",
    "fscore_result.columns=[\"fscore_score\"]\n",
    "fscore_result.sort_values(by=\"fscore_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
